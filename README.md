# Real world HTTP

## chapter1(HTTP/1.0のシンタックス：基本となる４つの要素)

* http(30x)のリダイレクトにはLocationヘッダーを使う
* urlを構成する文字はASCII文字列。UTF-8でURLエンコードすることで日本語も扱える。(漢字一文字がUTF-8で3バイト、URLエンコードで9バイト

## chapter2(HTTP/1.0のセマンティクス：ブラウザの基本機能の裏側)

* ファイルのアップロードでContent-Type(enctype): multipart/form-data;を使用する
* 実際のファイルの内容
  * ファイル名
  * ファイルの種類
  * 内容
* コンテントネゴシエーション(クライアントとサーバの認識合わせ)
  * image/webp
  * ```*/*,q=0.8```
  * qが品質係数で0から1までの数値
  * サーバがWebPに対応していればWebPを、そうでなければPNGなどの他のフォーマット(優先度0.8)をサーバに付与することを要求
  * サーバはリクエストで要求されたフォーマットの中からファイルを返します。優先順位を解釈し、上位から順番に対応しているフォーマットを探し、一致すればそのフォーマットで返します。もし、お互いに一致しているものがなければ406(not acceptable)エラーを返却
* HTTPのヘッダー上でコンテンツ(画像など)のネゴシエーションを行う
* BASIC認証、Digest認証のセッション管理は最近は使われない
  * 特定のフォルダ以下を「見せない」という使い方しかできず、トップページにユーザ固有の情報を出すようなことができない等
* 主流のセッション管理
  * クッキーにセッショントークンをもたせ、以降のリクエストではセッショントークンを一緒に送信してユーザ情報をわかりやすくしている
  * これによってユーザの個人情報をクッキー側に持たせなくても良くなった
  * 逆にCSRF(クロスサイトリクエストフォージェリ)の対策が必要になった
* Expiresというヘッダーを使うことでサーバにそもそもリクエストを送信しないように設定をすることができる
  * URLのリクエストの鮮度情報を持ち、ExpiresとLast-Modifiedヘッダーを比較してサーバにリクエストを送信
  * 注意点としてはExpiresはサーバに変更があったかどうかの問い合わせもしなくなるため、Expiresの期限までのコンテンツが一切見れなくなってしまう状況に陥ってしまう
* Pragmaヘッダーのno-cacheは途中のプロキシサーバに対して、「リクエストしたコンテンツがキャッシュされていたとしても、本来のサーバまでリクエストを届けてほしい」という指示(ただし、どこかのプロキシサーバがno-cacheになっていなかったら意味がなくなる)

## chapter4(HTTP/1.1のシンタックス：高速化安全性を求めた拡張)
* Keep-Aliveを使ってTCP/IPの通信を何度も再利用することができる
* パイプライニング
  * 最初のリクエストが完了する前に次のリクエストを送信し、「レスポンスを待って次のリクエストを出す」までの待ち時間を排除することでネットワークの稼働率を上げ、パフォーマンスを向上させる機能
  * Keep-Aliveの利用を前提としている
  * 今は殆ど使われていない
    * 実際の効果が感じられなかったり
	* Head-of-Line Blockingが発生したりした
* 通信所順を保持しなければならないという制約がHTTP/2でなくなった
  * サーバ側の準備が整った順序でレスポンスが返すことが可能になった
* ハッシュ関数
  * ファイルが壊れていないかを確認する方法として利用されたりしている
  * Gitでは、ファイルを管理する時にファイル名ではなくファイルの内容を元にしたハッシュ値を用いており、このハッシュ値をキーにしてファイルをDBに格納
  * ハッシュ値の衝突は極稀に起きるが、少ないデータ量であればほぼ起きない。
    * 衝突の起きにくさはアルゴリズムの良さの指標とされている
* 暗号のアルゴリズムで大事だとされていることは、アルゴリズムそのものを秘密にするの絵はなく、アルゴリズムが公開されていても安全に通信できること
* 共通鍵方式と公開鍵方式を使い分ける理由
  * 公開鍵方式のほうが手の混んでいる分、いかにも安全性が高そうです。
  * だがTLSは両方の方式を組み合わせている
  * TLSは通信ごとに一度だけ使われる共通鍵を作り出し、公開鍵方式を使って通信相手へ厳重に鍵を受け渡し、その後は共通鍵で高速に暗号化を行うという２段階の方式を利用している。
  * **公開鍵方式のほうが安全性は高いのですが、鍵を持っていたとしても暗号化と復号化に必要な計算量が共通鍵奉仕位に比べて大きすぎるため**
* TLSの通信手順
  1. サーバからSSLサーバ証明書を取得
  1. サーバ証明書の信頼性を認証局に確認
  1. クライアントで共通鍵を作成し証明書内の公開鍵で暗号化
  1. サーバで暗号化された鍵の復号化
  1. 復号した鍵で通信
* 通信の高速化
  * 通常の接続では、まずHTTPでつなぐ前のTCP/IPの段階で1.5RTT
  * その後のTLSのハンドシェイクで2RTT
  * その後のHTTPのリクエストで1RTT
  * ※ただし、TCP/IPの通信の最後の0.5RTTと、その後のTLSの最初の通信は一緒に行えるため、合計は4RTTとなる。TLSを使わなければ2RTTとなる。
  * TCPからUDPに置き換えて、再送処理をアプリケーションレイヤーのQUICと言う通信制御を行うことでハンドシェイクの手間がなくなり、0RTTとなる(Chromeでは実装されている
* TLSが守るもの
  * TLSは通信経路の安全を守るための仕組み
  * クライアントとサーバ間の通信経路が全く信頼できない状態でも安全な通信が行えるように設計されている
  * 通信経路が信頼できないというのは、中間者が通信を傍受したり、通信内容を自由に書き換えたり、クライアントと偽って代わりにリクエストを送ることが出来るということ -> TLSはその状態でも、納受も改ざんも詐称もされない通信を提供
  * 大切になるのは、共通鍵の安全な交換
  * 鍵交換の際の改ざんを防ぐために認証局を通す
* TRACE(TRACK) HTTPメソッド
  * 現在はほぼ使われていない
  * 任意のスクリプトをブラウザ上で実行するXSSの脆弱性と組み合わせて、BASIC認証のユーザ名やパスが奪取出来てしまうというクロスサイトトレーシング(XST)が有名になってからはTRACEメソッドを無効化する設定が数多い
* CONNECT HTTPメソッド
  * HTTPのプロトコル上に、他のプロトコルのパケットを流せるようにする
  * プロキシサーバ経由でターゲットのサーバに接続することを目的としている
  * 主にHTTPS通信を中継する用途で使われている **(HTTPS以外のCONNECT接続を拒否する使われ方** が多い
  * CONNECTメソッドを無条件で受け入れるプロキシは、どんなプロトコルでも通してしまうため、マルウェアがメールを送信したり刷る通信経路として使われる危険があります
* プロトコルのアップグレード
  * HTTP/1.1から可能になった
  * クライアント・サーバ側のどちらからでもアップグレードの要請が可能
  * 合計で3種類
    * HTTPからTLSを使った安全な通信へのアップグレード(TLS/1.0,1.1,1.2)
	* HTTPからWebsocketへ(websocket)
	* HTTPからHTTP/2へ(h2c)
  * クライアント側から要請
    * Upgrade/Connectionヘッダを含めたリクエストを送信
	  * Upgrade: TLS/1.0
	  * Connection: Upgrade
	* もしもサーバが対応していない場合は暗号化されていない問題があるので最初はOPTIONSメソッドのHTTPリクエストをサーバに送信しアップグレード可能かどうかの情報を取得する
  * サーバ側から要請
    * クライアント同様にUpgrade/Connectionヘッダを付加する
	* またステータスコードは426となる
* バーチャルホストへのサポート
  * HTTP/1.0まではホストなしでのルートディレクトリからのパスのみ(/hello)
  * HTTP/1.1からは、クライアントはHostヘッダに、リクエストを贈りたいサーバ名を記述することが必須になった(example.com/hello)みたいな？
  * これで一つのサーバ内に複数のサービスを混在させることが可能となった
* チャンク
  * HTTP/1.1からサポートされた
  * 全体を一括で送信するのではなく小分けにして送信する
  * ストリーミングダウンロード・アップロードと呼ばれることもある
  * 1GBの動画ファイルを送信刷る場合でも、メモリを1GB消費するようなことはない
  * クライアント側のメリットはサーバ側が最後のデータの準備ができたころには、それまでのデータが既に転送済みのためリードタイムを短く出来る
  * Transfer-Encoding: chunkedが設定されている時はContent-Lengthヘッダを含めてはいけないとRFCに定義されている
  * 最後に0を送信刷ると、そこでチャンクの転送が全て終わったというサインとなる

## chapter5(HTTP/1.1のセマンティクス：広がるHTTPの用途)
* HTTPはHTMLを取得してくるだけのプロトコルから、汎用的に使われるプロトコルへと応用範囲を広げている

### ファイルをダウンロードしたあとでローカルに保存
* ブラウザがファイルをどのように処理するのかを決めているのは、拡張子ではなくサーバから送られてくるMIMEタイプだった
* `Content-Disposition` ヘッダがあると、ブラウザは保存ああイアログを出してファイルを保存する
* filenameで指定されたファイル名が保存ダイアログのデフォルト値として表示されます
  * `Content-Disposition: attachment; filename=filename.xlsx`
  * `Content-Disposition: attachment; filename*=utf-8''ファイル名.xlsx; filename=filename.xlsx`

#### ダウンロードの仕組みについて
実際にファイルをダウンロードするサイトで、以下のような文面を見たことがありますか？

```
  ダウンロードありがとうございます。
  もしダウンロードが始まらない時はこちらをクリックしてください。
```

これの実現にサーバが2つのURLを提供している
* 実際にファイルをダウンロードするページでContent-Dispositionヘッダ付きでダウンロードするファイルをBodyで返す
* HTMLのページを返し、そこには上記のダウンロードありがとうのメッセージと、下記のヘッダーを含む
  * `<meta http-equiv="refresh" content="o;URL=./download_file">`

ブラウザがページを表示する時に、Content-Dispositionヘッダがあると、ページの表示をリセットせずにダウンロードだけを行います。
それを利用してダウンロード完了ページをユーザに見せることが出来る。

1. まずは完了ページをユーザに見せる
1. ブラウザはそのコンテンツを表示する時に、上記のメタタグを見つけるので、そのページにジャンプしようとする
1. ジャンプ先にはContent-Dispositionヘッダがあるので、ジャンプを指示したページをそのまま残してダウンロードが開始される


### XMLHttpRequest
* HTTP通信と同じく、クライアントがサーバにリクエストを送り、そのレスポンスとしてサーバからクライアントにデータを返信出来るというもの

#### XMLHttpRequestとブラウザのHTTPリクエストの違い
* 送受信時にHTMLの画面がリロードされない
* メソッドとして、GETとPOST以外も送信できる
* フォームの場合、キーと値が1対1になっている形式のデータしか送信できず、レスポンスはブラウザ表示されてしまうが、プレーンテキスト、JSON、バイナリ等のフォーマットで送信できる
* セキュリティのための制約がある

#### Comet
* XMLHttpRequestを駆使して、ほぼリアルタイムの双方向通信を行うテクニック
* レガシーな仕組みを応用しているため、比較的多くの環境で動作する
* 単方向通信を駆使して双方向通信を行うには2つの方法があります。
  * ポーリング
    * 通知を受ける側が、頻繁に通知がないか聞きに行く方式
    * 何度もリクエストを送信するためCPUを消費する(モバイル端末だと電力消費の温床)
  * ロングポーリング
    * 一度クライアントからサーバにリクエストが送られますが、その場でレスポンスを返すのではなく、返事を保留にしたままにします
    * HTTPの通信では、サーバ側から通信を完了させるかリクエストがタイム・アウトする前は、クライアント側にレスポンスが返ることはない
    * 接続を完了する権限がサーバにあることを応用し、サーバからのレスポンスを自由なタイミングで返すことで、サーバからのリクエストに見せかけて情報を送信する
    * リバースAjaxと呼ばれることもあった
* デメリット
  * HTTPはそもそもサーバ側からクライアントにメッセージを送る専用のAPIではなく、クッキーなども含めて大量のヘッダを付与して送受信する仕組みのため1メッセージのオーバーヘッドが大きい
  * 一度サーバからメッセージを受信すると、再びクライアント側からセッションを張り直さないと通信ができないためサーバからの連続したメッセージには強くない

#### XMLHttpRequestのセキュリティ
* XMLHttpRequestは強力なAPIのためセキュリティを掛けないと悪意のあるスクリプトなどが仕込まれたりする可能性が高い
* 2つの制限から成り立っている
  * アクセスできる情報の制御
    * cookieはdocument.cookieからアクセス可能で他のサイトにcookie情報を流出させることが可能。これをhttpOnly属性をcookieに付与するとスクリプトからアクセスできなくなる
  * 送信制限
    * ドメイン、メソッド、ヘッダーの3種類

### リモートプロシージャコール(RPC)
* リモートプロシージャコールというのは、別のコンピュータにある機能を、あたかも自分のコンピュータ内であるかのように呼び出しを行い、必要に応じて返り値を受け取る仕組み
* リモートメソッド呼び出しと呼ばれることもある

#### XML-RPC
* 送信に使うのはPOST(GETはキャッシュされてしまう可能性があるため不適合)
* 呼び出しの引数、返り値ともにXMLで表現するのでContent-Typeは常に `text/xml`

※ アプリケーションサーバの開発者の中には、HTTPのステータスコードとして200だけを返す流儀の人がいます。
これは、前段のリバースプロキシやApacheなどのシステムにうまくつながらない場合はステータスコードでエラーを返し、
アプリケーションは200 OKにしてXML内でエラーを返すことで、設定の問題でアプリケーションサーバまでリクエストが届いていないのか、
サーバコードがエラーを起こしているのかを切り分けやすくなるという考え

#### SOAP
* XML-RPCを拡張したもの
* XML-RPCよりも複雑になっている
* SOAPそのものはデータ表現フォーマット
* HTTP以外にもSMTPを使ってSOAPメッセージをやり取りすることも可能

#### JSON-RPC
* 記述がXMLよりもコンパクト
* TCP/IPソケットを使うことも想定している
* リクエスト時に必要なものはContent-Type,Content-Length,Acept
* 多くの場面においてPOSTを使用するのが望ましいとされているが冪等性があり安全なものであればGETも使える

#### WebDAV
* Microsoftが開発したHTTPを拡張することで分散ファイルシステムとして使えるようにしたもの
* WebDAVには用語がいくつかある
  * リソース：通常のFSではデータを格納する要素は「ファイル」だが、WebDAVは「リソース」と呼ぶ　
  * コレクション：フォルダやディレクトリに当たる
  * プロパティ：リソースやコレクションが持つことが出来る追加の属性で作成日時や最終更新者などがある
  * ロック：同一ファイルを同時編集してか







## chapter7(HTTP/2のシンタックス：プロトコルの再定義)
### Fetch API
* XMLHttpRequestよりも、オリジンサーバー外へのアクセス等、CORSの取扱が制御しやすい
* キャッシュ制御
* リダイレクト制御
* FetchAPIはセキュリティ向上。デフォルトでより厳格な設定が選択されており、必要に応じて明示的に解除する

#### ServiceWorker
* ServiceWorker内から外部サービスへの接続にはFetchAPIしか使えない仕様
* ProgressiveWebAppのひとつとして、アプリケーションのライフサイクルや通信内容をコントロールでいるようにするのがServiceWorker
* ServiceWorkerはウェブサービスのフロントエンドとサーバーの間で動く中間レイヤー

### Server-Sent Events
* HTML5の機能の一つ
* HTTP1.1の `Chunked形式` による通信
* Chunked形式は「少しずつ送信」と言う特徴
* ポーリング：クライアントから定期的にリクエストを送りサーバ側のイベントを検出
* ロングポーリング：リクエストを受け取った状態で返事を保留にする
* ロングポーリングとChunkedレスポンスを組み合わせて一度のリクエストに対して、サーバから複数のイベントの送信を実現する
* ポーリングは他の方法が使えなくなったときのフォールバック先として使用されており、後方互換性に問題はない
* サーバは `Last-Event-ID` ヘッダーを見て、クライアントがどこまで受信したのか判断
* JSは `EventSource` クラスを使って制御

### WebSocket
* サーバ・クライアント間でオーバーヘッドの小さい双方向通信を実現
* 一度通信が確率すると送信先の情報などは必要なくなる。（HTTPのbodyだけ送信してるようなもの
* HTTPの下のレイヤーであるTCPソケットに近い機能を提供するAPI群
* HTTPと違い「ステートフル」
* メモリ上にデータを持った状態で通信するケースが多く、LBを単純に使えない
* 一度接続が切れた場合はデータが存在しているサーバに再接続しなければならない
* 対応手段としてはTCPレベルのLBを使ったり、専用のLBを利用したりする
* WSを使う時は最初はHTTP通信を行い `Upgrade` ヘッダーを使ってWSにプロトコルを変更
* `Socket.IO` というWSのラッパーライブラリがあり、後方互換性を持ちつつ、XMLHttpRequestによるロングポーリングのフォールバック等を持つ便利なライブラリだったが、最近はほぼ全てのブラウザでWSが使えるため、今後はSocket.IOはあまり使われないだろう

## chapter8(HTTP/2のセマンティクス：新しいユースケース)
### オープングラフプロトコル
* SNSで使われるメタデータで、Facebookが開発した
* オープングラフプロトコルが設定されているウェブサイトのURLをSNS等で貼り付けると、記事の一部や画像が表示される
* 具体亭にはHTMLのheaderタグ内にmetaタグとして情報を設定する
  * `<meta property="og:image" content="http://example.com/rock.jpg" />`
  * `<meta property="og:title" content="タイトル" />`

### AMP
* モバイルの高速化のための仕組み
* どんなページでも高速化刷るわけではなく、適した場所が決まっている
  * Google:AMPはあらゆるタイプの静的なウェブコンテンツで大きな効果を発揮します。一方、動的で双方向性を重視した単一ページのサービスにはあまり効果的ではありません。
* AMPは作り方を厳しい制約を課している
  * JavaScriptを自由に使えず、スクリプトで指定されたサブセットなどを使う
  * Ajaxであとからコンテンツを取得することもできない
* クローラーがコンテンツを見つけた時にAMPである、もしくは\<link\>タグの先にAMPページが有ることを認識すると、GoogleのCDNにコピーすることでAMPが高速化されている

### HTTPライブストリーミング(HLS)
* ほぼリアルタイム中継などのストリーミングに使用可能
* 通信回線に合わせて適切な解像度の動画を選択できる
* 字幕、音声の切り替えにも対応
* MPEG2-TSを仕様(地上デジタル)
* HTML上で再生するというよりも、ブラウザ自身にHLSの `.m3u8` ファイルを解釈して再生するシステムが組み込まれている(MediaPlayerフレームワークを利用することで、ブラウザ以外でも再生可

#### メリット
* サーバとクライアントに特別んプロトコルはなくHTTPを利用している
* HTTPなのでコンテンツ配信ネットワークも同じように使える
* サーバ側で必要な設定は、MIMEタイプとTTLのみ

#### デメリット
* *ストリーム* と言っているが実態はプログレッシブダウンロード方式になっている
* そのためチャンクごとにDLが完了しないと再生が始められない為、遅延が発生する
* 大きいデメリットはサポートされていない環境が多いこと
  * 特にデスクトップ版はFlashが共通のツールとして使われてきたから重要度が高くなかった為
  * 他には動画フォーマットが固定されていたり、コンテンツ保護のDRMに制約がある点が挙げられる

#### MPEG-DASH(Dynamic Adaptive Streaming over HTTP)
* HLSを大幅に拡張した規格として登場
* HTTPによるプログレッシブダウンロードを書くとしたストリーミング方式
* ブラウザ自身がプロトコルを直接解釈するのではなく、データの解析をJavaScriptが行い、動画の再生はブラウザのコーデックをJavaScriptから扱うAPIを利用
  * HTML5 Media Source Extensions
  * HTML5 Encrypted Media Extensions(暗号化機能)
* 2016年にAppleはMPEG-DASH側に譲歩する発表を行った

## chapter10(セキュリティ：ブラウザを守るHTTPの機能)
* ブラウザでセッションを保持する仕組みとして広く使われているのがクッキー
* サーバとブラウザの関係を一位に決めるものはトークン
* クッキーに格納されるユニークなIDのデータをセッショントークン、その入れ物をクッキーとして説明。これが奪われると「ログイン済み」と扱われるためセキュリティの要と言える

### XSS
* XSSを起点としたたくさんのマルウェアが存在しているためかなりクリティカルな攻撃方法
* 対策としては
  * ユーザの入力情報をそのまま出力しないこと
  * クッキーにhttpOnly属性を付与する(これによりJSからクッキーにアクセスできなくなる
  * X-XSS-Protectionヘッダーを使うことで明らかにあやしいパターンを検出する
    * Xのプレフィックスなので公式ではないが、ほぼデファクトスタンダードとなっている
* サニタイズ（消毒）とはユーザ入力は悪意を持った入力が来るものとみなし、きれいにしてから利用すること
* 現在ではサニタイズよりも出力直前にきれいにするエスケープする方法が一般的
  * 出力はHTML,SQL,コマンド等多岐に渡る(SQLインジェクション、コマンドインジェクション等

#### Content-Security-Policyヘッダー
* ウェブサイトで使える機能を細かくON/OFFできる仕組みの事
* ウェブサイトで必要となる機能をサーバから設定することで、XSS等のJSが想定外に動作することを抑制する
* Content-Security-Policyヘッダーは便利だが、強力すぎて正常の動作を妨害することがある
  * 段階的に移行するための機構としてContent-Security-Policy-Report-Onlyヘッダーがある
  * このヘッダーはチェックは行うが、動作は止まらなくなります
  * `upgrade-insecure-requests` ディレクティブを使うことで根本的に全てのリクエストをHTTPSに修正する以外の対応が可能
    * `Content-Security-Policy: upgrade-insecure-requests`

#### CORS(クロスオリジンリソースシェアリング)
* クライアントからサーバにアクセスする直前までの権限確認プロトコル
* 守る対象はAPIサーバ
* 許可していないウェブサイトから利用されてしまう「タダ乗り」を防ぐ
* JS上でわかるリクエストの結果としては「通信実行」と「失敗」の2つ
* 大まかなフロー
  * simple cross-origin request
    * 下記の条件を満たせない場合はプリフライトリクエストが必須
    * HTTPのリクエストのメソッドがシンプルメソッド(GET,POST,HEAD)
	* ヘッダーがシンプルヘッダーのみ(Accept,Accept-Language,Content-Language,Content-Type以外を含まない)
	* Content-Typeを含む場合、その値がapplication/x-www-form-urlencoded,multipart/form-data,text-plainのどれか)
  * プリフライトリクエストを伴う actual request
    * プリフライトリクエストの際には下記のヘッダーをつけてOPTIONメソッドで送信
	* Access-Control -Request-Methodリクエストヘッダ
	  * 通信を許可してもらいたいメソッドを指定
	* Access-Control-Request-Headersリクエストヘッダ
	  * 許可して欲しいヘッダーをカンマ区切りで列挙
	* Originレスポンスヘッダ
	  * 通信元のウェブページのドメイン名を指定
  * クロスオリジンの通信のデフォルトではクッキーを送受信しない
  * -> クライアントで送信することが設定済みのFetchAPIで、サーバが許可する場合のみ送信する

### 中間者攻撃
* プロキシサーバが通信を中継する時に通信内容を抜き取られることで情報が漏洩してしまう問題
* 対処するためにはHTTPS(TLS)を利用するしかない
* TLSは「通信経路が信頼できない」状態でもセキュリティを維持したまま通信が行えるようにする仕組み

#### HSTS(HTTP Strict Transport Security)
* 中間者攻撃に対抗するためのHTTPの仕組みの一つ
* 「今後接続する時はHTTPSで接続して欲しい」とサーバ側から伝達する仕組み
* `Strict-Transport-Security: max-age=31536000;includeSubDomains` で要請可能
  * includeSubDomainsがあると、ブラウザに対してサブドメインも移行対象であることを伝える
  * ブラウザが指定されたサイトへアクセスする時、自動的にHTTPSサイトへ接続する
  * また有効期限がmax-ageで設定され、今回は一年間この設定が有効となる
* HSTSの欠点は初回はHTTP通信になってしまうこと
  * 初回にマルウェアを仕込まれると検知することができない
  * この問題の対処として、GoogleChromeで最初からHTTPSでアクセスできる設定するための申請フォームを作成している

#### HTTP公開鍵ピンニング
* ピンニングはピン留めの意味
* TLSの公開鍵のリストを初回アクセスで送付してもらい、手元にピン留めして保存
* 二回目移行のアクセス時に、サーバが送ってきた証明書の公開鍵と比較し不正がないか検知する
* これは中間者が持つ証明書がTLSで承認されてしまった時にブラウザが検知刷ることができない問題を解決してくれる　

### セッションハイジャック
* セッショントークンを盗み出しサイトにログインする攻撃
* 対策としてはHTTPS化、Set-Cookie: httpOnly, secure などを付与する

#### クッキーインジェクション
* もともとのクッキー情報をHTTPSのサブドメインや元のURLよりも詳細URLのクッキーを設定することで無効化してしまう事
* これによりセッション固定化攻撃の温床になったりする

### CSRF(クロスサイトリクエストフォージュリ)
* 本人が意図しないサーバリクエストを、無関係のページやサイトから送らせることができる
* 実際にリクエストを送るのは攻撃者ではなく被害ユーザ
* 他のユーザに殺害予告を書き込ませて、無実の人を犯人に仕立て上げるような事件が発生しました

#### CSRF対策トークン
* 隠しフィールド(typeがhiddenなフィールド)に、ランダムに作成したトークンを埋め込み、POSTのリクエストを受け取るサーバ側で、正しいトークンが含まれていないリクエストを全て拒絶するという対応を取る

### クリックジャッキング
* iframeを使い、正常なページの上に透明な悪意のあるサイトを表示させ、クリックを起因に悪意のあるサイトに対して操作をしてしまう
* iframeを使い、悪意のあるページの上に正常なページの上に重ね、シェアボタンと重なるように悪意のあるサイトのタグを配置し、CSRFのような挙動を実行させる

#### X-Frame-Optionsヘッダ
* クリックジャッキングの対抗手段でページがIFRAME内で利用されることを防ぐ
  * DENY: フレーム内で使われることを拒否する
  * SAMEORIGIN: 同一URL以外のフレーム内で使われることを拒否する
  * ALL-FROM http://example.com: 指定されたURLから呼び出される場合に限り、フレーム内での表示を許可する



## curl

### オプション

* -H
  * HTTPリクエストにヘッダー情報を書き込む
  * 同名のヘッダーに対して複数書き込んだ場合はサーバによるが文字列か配列として処理される
* -v
  * サーバとクライアントの情報のフローをより詳細に確認することができる
* -X method
  * HTTPリクエストで利用するメソッドを任意に指定
* -d,--data
  * 素のテキストデータをリクエストに含める
* -F
  * multipart/form-dataが設定された形式でリクエストを送信
* --data-urlencode
  * curlコマンドがテキストデータを" エンコードしてリクエストを送信
* --compressed
  * データ圧縮する
* -J/--remote-header-name
  * Content-Dispositionヘッダで設定された名前を使ってローカルに保存する
  * ただし、URLエンコードのデコードはしないため `%20` などがあると、そのまま出力される
  * 同名ファイルが存在する場合はブラウザのように `filename(2).xlsx` のようにはならずエラーとなる
* -O/--remote-name
  * URLそのままの名前で保存する。何もつけないと、ファイルに保存せずにコンソールに出力する


### サンプル

* json形式のリクエストを送信(普通のリクエストだとContent-Typeが```application/x-www-form-urlencoded```)

```
 $ curl -d "{\"hello\": \"world\"}" -H "Content-Type:application/json http://localhost:18888
```

* jsonファイルを使ってリクエストを送信する

```
 $ curl -d @test.json -H "Content-Type: application/json http://localhost:18888
```

* ファイルをアップロード
```
 $ curl --http1.0 -F attachment-file@test.txt
```

* ファイルを保存
```
  $ curl -O http://example.com/download/sample.pdf
```
